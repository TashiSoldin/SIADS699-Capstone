{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1gtGsZXjENv"
      },
      "source": [
        "# Notebook 4: Model Development, Optimisation, and Interpretation\n",
        "\n",
        "**Notebook Purpose**\n",
        "This notebook develops, optimizes, and interprets the main predictive models:\n",
        "1. Train multiple model types (including Random Forest, XGBoost, Neural Networks)\n",
        "2. Hyperparameter tuning using validation set performance\n",
        "3. Cross-validation with TimeSeriesSplit to respect temporal ordering\n",
        "4. Model comparison and selection based on validation metrics\n",
        "5. Feature importance analysis to identify which spectral bands predict oxygen\n",
        "\n",
        "**Key Outputs**\n",
        "- `best_model.pkl`: Trained best-performing model\n",
        "- Feature importance rankings and visualizations (SHAP, permutation importance)\n",
        "- Validation set performance metrics\n",
        "- Insights about satellite derived features-oxygen relationships\n",
        "\n",
        "**Data Leakage Prevention**\n",
        "All training, hyperparameter tuning, and model selection use validation set only. TimeSeriesSplit prevents look-ahead bias in cross-validation. Test set remains unsued until Notebook 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CwmP4xrjH-L"
      },
      "source": [
        "## Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8EmBOTHNjKjF",
        "outputId": "fe3251a9-ce05-4c58-f5db-749e2f24f1bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_HH8A777qLkR"
      },
      "source": [
        "## Data Ingestion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ozeO3IR6qMlr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "outputId": "04d67105-9312-4fe4-9b6f-01bb6e257079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Latitude  Longitude  Year  Month  Day   chlor_a         poc        sst  \\\n",
              "0   54.6230    13.0280  2002      7    4  3.398178  274.399994  15.715000   \n",
              "1   54.5960    18.7737  2002      7    4  3.311782  242.399994  16.369999   \n",
              "2   54.5777    18.7477  2002      7    4  5.786841  294.200012  16.100000   \n",
              "3   54.5700    18.6800  2002      7    4  5.830627  295.600006  16.010000   \n",
              "4   54.5782    18.6610  2002      7    4  5.830627  295.600006  16.010000   \n",
              "\n",
              "    Rrs_412   Rrs_443  ...  sst_squared    sst_cubed  log_chlor_a   log_poc  \\\n",
              "0  0.002476  0.001970  ...   246.961230  3880.995764     1.223239  5.614587   \n",
              "1  0.002618  0.002244  ...   267.976865  4386.780994     1.197486  5.490589   \n",
              "2  0.002444  0.001922  ...   259.210012  4173.281297     1.755587  5.684260   \n",
              "3  0.002370  0.001860  ...   256.320107  4103.684977     1.763125  5.689007   \n",
              "4  0.002370  0.001860  ...   256.320107  4103.684977     1.763125  5.689007   \n",
              "\n",
              "   ratio_443_547  ratio_443_555  sst_chlor_interaction  abs_latitude  season  \\\n",
              "0       0.714286       0.755368              19.223206       54.6230  Summer   \n",
              "1       0.804301       0.843609              19.602851       54.5960  Summer   \n",
              "2       0.669687       0.704029              28.264945       54.5777  Summer   \n",
              "3       0.665712       0.700301              28.227624       54.5700  Summer   \n",
              "4       0.665712       0.700301              28.227624       54.5782  Summer   \n",
              "\n",
              "   Oxygen  \n",
              "0   278.0  \n",
              "1   322.0  \n",
              "2   320.0  \n",
              "3   328.0  \n",
              "4   328.0  \n",
              "\n",
              "[5 rows x 29 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8606d64f-6b87-4eeb-b0ef-9d13daca9654\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latitude</th>\n",
              "      <th>Longitude</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>chlor_a</th>\n",
              "      <th>poc</th>\n",
              "      <th>sst</th>\n",
              "      <th>Rrs_412</th>\n",
              "      <th>Rrs_443</th>\n",
              "      <th>...</th>\n",
              "      <th>sst_squared</th>\n",
              "      <th>sst_cubed</th>\n",
              "      <th>log_chlor_a</th>\n",
              "      <th>log_poc</th>\n",
              "      <th>ratio_443_547</th>\n",
              "      <th>ratio_443_555</th>\n",
              "      <th>sst_chlor_interaction</th>\n",
              "      <th>abs_latitude</th>\n",
              "      <th>season</th>\n",
              "      <th>Oxygen</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>54.6230</td>\n",
              "      <td>13.0280</td>\n",
              "      <td>2002</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3.398178</td>\n",
              "      <td>274.399994</td>\n",
              "      <td>15.715000</td>\n",
              "      <td>0.002476</td>\n",
              "      <td>0.001970</td>\n",
              "      <td>...</td>\n",
              "      <td>246.961230</td>\n",
              "      <td>3880.995764</td>\n",
              "      <td>1.223239</td>\n",
              "      <td>5.614587</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.755368</td>\n",
              "      <td>19.223206</td>\n",
              "      <td>54.6230</td>\n",
              "      <td>Summer</td>\n",
              "      <td>278.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>54.5960</td>\n",
              "      <td>18.7737</td>\n",
              "      <td>2002</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>3.311782</td>\n",
              "      <td>242.399994</td>\n",
              "      <td>16.369999</td>\n",
              "      <td>0.002618</td>\n",
              "      <td>0.002244</td>\n",
              "      <td>...</td>\n",
              "      <td>267.976865</td>\n",
              "      <td>4386.780994</td>\n",
              "      <td>1.197486</td>\n",
              "      <td>5.490589</td>\n",
              "      <td>0.804301</td>\n",
              "      <td>0.843609</td>\n",
              "      <td>19.602851</td>\n",
              "      <td>54.5960</td>\n",
              "      <td>Summer</td>\n",
              "      <td>322.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>54.5777</td>\n",
              "      <td>18.7477</td>\n",
              "      <td>2002</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>5.786841</td>\n",
              "      <td>294.200012</td>\n",
              "      <td>16.100000</td>\n",
              "      <td>0.002444</td>\n",
              "      <td>0.001922</td>\n",
              "      <td>...</td>\n",
              "      <td>259.210012</td>\n",
              "      <td>4173.281297</td>\n",
              "      <td>1.755587</td>\n",
              "      <td>5.684260</td>\n",
              "      <td>0.669687</td>\n",
              "      <td>0.704029</td>\n",
              "      <td>28.264945</td>\n",
              "      <td>54.5777</td>\n",
              "      <td>Summer</td>\n",
              "      <td>320.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>54.5700</td>\n",
              "      <td>18.6800</td>\n",
              "      <td>2002</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>5.830627</td>\n",
              "      <td>295.600006</td>\n",
              "      <td>16.010000</td>\n",
              "      <td>0.002370</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>...</td>\n",
              "      <td>256.320107</td>\n",
              "      <td>4103.684977</td>\n",
              "      <td>1.763125</td>\n",
              "      <td>5.689007</td>\n",
              "      <td>0.665712</td>\n",
              "      <td>0.700301</td>\n",
              "      <td>28.227624</td>\n",
              "      <td>54.5700</td>\n",
              "      <td>Summer</td>\n",
              "      <td>328.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>54.5782</td>\n",
              "      <td>18.6610</td>\n",
              "      <td>2002</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>5.830627</td>\n",
              "      <td>295.600006</td>\n",
              "      <td>16.010000</td>\n",
              "      <td>0.002370</td>\n",
              "      <td>0.001860</td>\n",
              "      <td>...</td>\n",
              "      <td>256.320107</td>\n",
              "      <td>4103.684977</td>\n",
              "      <td>1.763125</td>\n",
              "      <td>5.689007</td>\n",
              "      <td>0.665712</td>\n",
              "      <td>0.700301</td>\n",
              "      <td>28.227624</td>\n",
              "      <td>54.5782</td>\n",
              "      <td>Summer</td>\n",
              "      <td>328.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 29 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8606d64f-6b87-4eeb-b0ef-9d13daca9654')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8606d64f-6b87-4eeb-b0ef-9d13daca9654 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8606d64f-6b87-4eeb-b0ef-9d13daca9654');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5ea980c0-002d-4f3f-a701-66c66e95bd3e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5ea980c0-002d-4f3f-a701-66c66e95bd3e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5ea980c0-002d-4f3f-a701-66c66e95bd3e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "training_set_file_path = '/content/drive/MyDrive/Colab Notebooks/MADS/SIADS 699/Data/Data Splits/Processed/Training Set.csv'\n",
        "validation_set_file_path = '/content/drive/MyDrive/Colab Notebooks/MADS/SIADS 699/Data/Data Splits/Processed/Validation Set.csv'\n",
        "testing_set_file_path = '/content/drive/MyDrive/Colab Notebooks/MADS/SIADS 699/Data/Data Splits/Processed/Testing Set.csv'\n",
        "\n",
        "training_df = pd.read_csv(training_set_file_path)\n",
        "validation_df = pd.read_csv(validation_set_file_path)\n",
        "testing_df = pd.read_csv(testing_set_file_path)\n",
        "\n",
        "training_df.head()\n",
        "# validation_df.head()\n",
        "# testing_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw0S2HHf4hf4"
      },
      "source": [
        "# Helper functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O5U_eDxN4iwd"
      },
      "outputs": [],
      "source": [
        "def add_datetime_and_sort(df):\n",
        "    df = df.copy()\n",
        "    df[\"__dt__\"] = pd.to_datetime(\n",
        "        dict(year=df[\"Year\"], month=df[\"Month\"], day=df[\"Day\"]),\n",
        "        errors='coerce'\n",
        "    )\n",
        "    df = df.sort_values(\"__dt__\").reset_index(drop=True)\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HhlMvE87PLu"
      },
      "outputs": [],
      "source": [
        "training_df,validation_df = add_datetime_and_sort(training_df),add_datetime_and_sort(validation_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yDKGG1FPqaEj"
      },
      "source": [
        "## Advanced Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVpY14PHvp8O"
      },
      "source": [
        "Linear Regression variant: elastic net We chose to switch to elastic net here as it is more tuneable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2uYYBCjqaZF"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def elastic_net_model(training_df,validation_df,target_col='Oxygen'):\n",
        "  X_train=training_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_train=training_df[target_col]\n",
        "\n",
        "  X_val=validation_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_val=validation_df[target_col]\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "              (\"scaler\", StandardScaler())\n",
        "          ]), selector(dtype_include=np.number)),\n",
        "          (\"cat\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "              (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "          ]), selector(dtype_exclude=np.number)),\n",
        "      ],\n",
        "      remainder=\"drop\"\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  elastic_net = ElasticNet()\n",
        "  model = Pipeline([\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"regressor\", elastic_net)\n",
        "  ])\n",
        "  param_grid = {\n",
        "        \"regressor__alpha\": [0.001, 0.01, 0.1, 1.0, 10.0],\n",
        "        \"regressor__l1_ratio\": [0.1, 0.3, 0.5, 0.7, 0.9]\n",
        "    }\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=tscv, scoring='neg_root_mean_squared_error',n_iter=10, n_jobs=1)\n",
        "\n",
        "  random_search.fit(X_train, y_train)\n",
        "  best_params = random_search.best_params_\n",
        "  print(f\"Best paramters:{best_params}\")\n",
        "  best_model = random_search.best_estimator_\n",
        "  y_pred_train = best_model.predict(X_train)\n",
        "  rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "  mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "  r2_train = r2_score(y_train, y_pred_train)\n",
        "  y_pred = best_model.predict(X_val)\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "  mae = mean_absolute_error(y_val, y_pred)\n",
        "  r2 = r2_score(y_val, y_pred)\n",
        "  print(f'RMSE for training: {rmse_train}')\n",
        "  print(f'R2 for training: {r2_train}')\n",
        "  print(f'MAE for training: {mae_train}')\n",
        "\n",
        "  print(f'RMSE: {rmse}')\n",
        "  print(f'R2: {r2}')\n",
        "  print(f'MAE: {mae}')\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mz-80MD4v2Lj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fff325c-ade7-47e6-d73b-e109528423a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2277863.4694107994, tolerance: 1628.5119620611356\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5513257.371299884, tolerance: 3729.224071665968\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9764358.001576375, tolerance: 5666.532873166675\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13916787.130057871, tolerance: 7909.299435009871\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16880054.413216762, tolerance: 9826.005814106054\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2462809.7909375215, tolerance: 1628.5119620611356\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5978215.379840637, tolerance: 3729.224071665968\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10670131.979012152, tolerance: 5666.532873166675\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15349649.857014298, tolerance: 7909.299435009871\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18630592.599669833, tolerance: 9826.005814106054\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n",
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_coordinate_descent.py:656: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19267641.586967725, tolerance: 11774.556991361726\n",
            "  model = cd_fast.sparse_enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best paramters:{'regressor__l1_ratio': 0.5, 'regressor__alpha': 0.001}\n",
            "RMSE for training: 35.952875514070406\n",
            "R2 for training: 0.6516904495060571\n",
            "MAE for training: 21.009451734247023\n",
            "RMSE: 42.399076367897216\n",
            "R2: 0.5392769127359354\n",
            "MAE: 26.185307814285363\n"
          ]
        }
      ],
      "source": [
        "model_en = elastic_net_model(training_df, validation_df, target_col='Oxygen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9S3AY-_vtWs"
      },
      "source": [
        "Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGfGab_Svv59"
      },
      "outputs": [],
      "source": [
        "\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "def random_forest_model(training_df,validation_df,target_col='Oxygen'):\n",
        "  X_train=training_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_train=training_df[target_col]\n",
        "\n",
        "  X_val=validation_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_val=validation_df[target_col]\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "              (\"scaler\", StandardScaler())\n",
        "          ]), selector(dtype_include=np.number)),\n",
        "          (\"cat\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "              (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "          ]), selector(dtype_exclude=np.number)),\n",
        "      ],\n",
        "      remainder=\"drop\"\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  rand_forest = RandomForestRegressor()\n",
        "  model = Pipeline([\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"regressor\", rand_forest)\n",
        "  ])\n",
        "\n",
        "  param_grid = {\n",
        "        'regressor__n_estimators': [100, 200, 300],\n",
        "        'regressor__max_depth': [None, 10, 20],\n",
        "        'regressor__min_samples_split': [2, 5, 10],\n",
        "        'regressor__min_samples_leaf': [1, 2, 4],\n",
        "        'regressor__bootstrap': [True, False]\n",
        "    }\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=tscv, scoring='neg_root_mean_squared_error',n_iter=10, n_jobs=1)\n",
        "\n",
        "  random_search.fit(X_train, y_train)\n",
        "  best_params = random_search.best_params_\n",
        "  print(f\"Best paramters:{best_params}\")\n",
        "  best_model = random_search.best_estimator_\n",
        "  y_pred_train = best_model.predict(X_train)\n",
        "  rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "  mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "  r2_train = r2_score(y_train, y_pred_train)\n",
        "  y_pred = best_model.predict(X_val)\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "  mae = mean_absolute_error(y_val, y_pred)\n",
        "  r2 = r2_score(y_val, y_pred)\n",
        "  print(f'RMSE for training: {rmse_train}')\n",
        "  print(f'R2 for training: {r2_train}')\n",
        "  print(f'MAE for training: {mae_train}')\n",
        "\n",
        "  print(f'RMSE: {rmse}')\n",
        "  print(f'R2: {r2}')\n",
        "  print(f'MAE: {mae}')\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JVLvwngBvzqM"
      },
      "outputs": [],
      "source": [
        "model_rf = random_forest_model(training_df, validation_df, target_col='Oxygen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOmPXs5lwXwV"
      },
      "source": [
        "LGBM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yceewEwAwP06"
      },
      "outputs": [],
      "source": [
        "!pip install lightgbm\n",
        "from lightgbm import LGBMRegressor\n",
        "def lgbm_model(training_df,validation_df,target_col='Oxygen'):\n",
        "  X_train=training_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_train=training_df[target_col]\n",
        "\n",
        "  X_val=validation_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_val=validation_df[target_col]\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "              (\"scaler\", StandardScaler())\n",
        "          ]), selector(dtype_include=np.number)),\n",
        "          (\"cat\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "              (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "          ]), selector(dtype_exclude=np.number)),\n",
        "      ],\n",
        "      remainder=\"drop\"\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  lgbm = LGBMRegressor()\n",
        "  model = Pipeline([\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"regressor\", lgbm)\n",
        "  ])\n",
        "\n",
        "  param_grid = {\n",
        "      'regressor__num_leaves': [20, 31, 40],\n",
        "      'regressor__max_depth': [5, 7, -1],\n",
        "      'regressor__learning_rate': [0.01, 0.05, 0.1],\n",
        "      'regressor__n_estimators': [100, 200, 500],\n",
        "      'regressor__colsample_bytree': [0.7, 0.8, 0.9],\n",
        "      'regressor__subsample': [0.7, 0.8, 0.9],\n",
        "  }\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=tscv, scoring='neg_root_mean_squared_error',n_iter=10, n_jobs=1)\n",
        "\n",
        "  random_search.fit(X_train, y_train)\n",
        "  best_params = random_search.best_params_\n",
        "  print(f\"Best paramters:{best_params}\")\n",
        "  best_model = random_search.best_estimator_\n",
        "  y_pred_train = best_model.predict(X_train)\n",
        "  rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "  mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "  r2_train = r2_score(y_train, y_pred_train)\n",
        "  y_pred = best_model.predict(X_val)\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "  mae = mean_absolute_error(y_val, y_pred)\n",
        "  r2 = r2_score(y_val, y_pred)\n",
        "  print(f'RMSE for training: {rmse_train}')\n",
        "  print(f'R2 for training: {r2_train}')\n",
        "  print(f'MAE for training: {mae_train}')\n",
        "\n",
        "  print(f'RMSE: {rmse}')\n",
        "  print(f'R2: {r2}')\n",
        "  print(f'MAE: {mae}')\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91_Pn7gCw-4D"
      },
      "outputs": [],
      "source": [
        "model_lgbm = lgbm_model(training_df, validation_df, target_col='Oxygen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7y9P9ygxEtP"
      },
      "source": [
        "Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-n9wLzkkxD3J"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "def nn_model(training_df,validation_df,target_col='Oxygen'):\n",
        "  X_train=training_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_train=training_df[target_col]\n",
        "\n",
        "  X_val=validation_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_val=validation_df[target_col]\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "              (\"scaler\", StandardScaler())\n",
        "          ]), selector(dtype_include=np.number)),\n",
        "          (\"cat\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "              (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "          ]), selector(dtype_exclude=np.number)),\n",
        "      ],\n",
        "      remainder=\"drop\"\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  mlp = MLPRegressor(\n",
        "        hidden_layer_sizes=(256, 128,64),\n",
        "        activation='relu',\n",
        "        solver='adam',\n",
        "        max_iter=500,\n",
        "        random_state=42\n",
        "    )\n",
        "  model = Pipeline([\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"regressor\", mlp)\n",
        "  ])\n",
        "\n",
        "  param_grid = {\n",
        "      'regressor__hidden_layer_sizes': [(50,), (100, 50), (200, 100, 50)],\n",
        "      'regressor__activation': ['relu', 'tanh', 'logistic'],\n",
        "      'regressor__solver': ['adam', 'sgd'],\n",
        "      'regressor__alpha': [0.0001, 0.001, 0.01],\n",
        "      'regressor__learning_rate_init': [0.001, 0.01],\n",
        "      'regressor__max_iter': [200, 500]\n",
        "  }\n",
        "\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=tscv, scoring='neg_root_mean_squared_error',n_iter=10, n_jobs=1)\n",
        "\n",
        "  random_search.fit(X_train, y_train)\n",
        "  best_params = random_search.best_params_\n",
        "  print(f\"Best paramters:{best_params}\")\n",
        "  best_model = random_search.best_estimator_\n",
        "  y_pred_train = best_model.predict(X_train)\n",
        "  rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "  mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "  r2_train = r2_score(y_train, y_pred_train)\n",
        "  y_pred = best_model.predict(X_val)\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "  mae = mean_absolute_error(y_val, y_pred)\n",
        "  r2 = r2_score(y_val, y_pred)\n",
        "  print(f'RMSE for training: {rmse_train}')\n",
        "  print(f'R2 for training: {r2_train}')\n",
        "  print(f'MAE for training: {mae_train}')\n",
        "\n",
        "  print(f'RMSE: {rmse}')\n",
        "  print(f'R2: {r2}')\n",
        "  print(f'MAE: {mae}')\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROMOPDQ8xjdf"
      },
      "outputs": [],
      "source": [
        "model_nn = nn_model(training_df, validation_df, target_col='Oxygen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aD_FzF711tVY"
      },
      "source": [
        "XGBoosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5CjftNgc1vXM"
      },
      "outputs": [],
      "source": [
        "from xgboost import XGBRegressor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmsVY4gm1_SZ"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "def xgb_model(training_df,validation_df,target_col='Oxygen'):\n",
        "  X_train=training_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_train=training_df[target_col]\n",
        "\n",
        "  X_val=validation_df.drop(target_col, axis=1)\n",
        "\n",
        "  y_val=validation_df[target_col]\n",
        "\n",
        "  preprocessor = ColumnTransformer(\n",
        "      transformers=[\n",
        "          (\"num\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "              (\"scaler\", StandardScaler())\n",
        "          ]), selector(dtype_include=np.number)),\n",
        "          (\"cat\", Pipeline([\n",
        "              (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
        "              (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "          ]), selector(dtype_exclude=np.number)),\n",
        "      ],\n",
        "      remainder=\"drop\"\n",
        "  )\n",
        "\n",
        "\n",
        "\n",
        "  xgb = XGBRegressor(\n",
        "        n_estimators=500,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        reg_lambda=1.0,\n",
        "        random_state=42,\n",
        "        objective='reg:squarederror',\n",
        "        n_jobs=-1\n",
        "    )\n",
        "  model = Pipeline([\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"regressor\", xgb)\n",
        "  ])\n",
        "\n",
        "  param_grid = {\n",
        "      'regressor__n_estimators': [100, 200, 300],\n",
        "      'regressor__learning_rate': [0.01, 0.1, 0.2],\n",
        "      'regressor__max_depth': [3, 5, 7],\n",
        "      'regressor__subsample': [0.7, 0.9],\n",
        "      'regressor__colsample_bytree': [0.7, 0.9],\n",
        "      'regressor__gamma': [0, 0.1, 0.2],\n",
        "      'regressor__reg_alpha': [0, 0.005, 0.01],\n",
        "      'regressor__reg_lambda': [1, 1.5, 2]\n",
        "  }\n",
        "  tscv = TimeSeriesSplit(n_splits=5)\n",
        "  random_search = RandomizedSearchCV(estimator=model, param_distributions=param_grid, cv=tscv, scoring='neg_root_mean_squared_error',n_iter=10, n_jobs=1)\n",
        "\n",
        "  random_search.fit(X_train, y_train)\n",
        "  best_params = random_search.best_params_\n",
        "  print(f\"Best paramters:{best_params}\")\n",
        "  best_model = random_search.best_estimator_\n",
        "  y_pred_train = best_model.predict(X_train)\n",
        "  rmse_train = np.sqrt(mean_squared_error(y_train, y_pred_train))\n",
        "  mae_train = mean_absolute_error(y_train, y_pred_train)\n",
        "  r2_train = r2_score(y_train, y_pred_train)\n",
        "  y_pred = best_model.predict(X_val)\n",
        "  rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
        "  mae = mean_absolute_error(y_val, y_pred)\n",
        "  r2 = r2_score(y_val, y_pred)\n",
        "  print(f'RMSE for training: {rmse_train}')\n",
        "  print(f'R2 for training: {r2_train}')\n",
        "  print(f'MAE for training: {mae_train}')\n",
        "\n",
        "  print(f'RMSE: {rmse}')\n",
        "  print(f'R2: {r2}')\n",
        "  print(f'MAE: {mae}')\n",
        "  return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nPGYBN0B20In"
      },
      "outputs": [],
      "source": [
        "model_xgb = xgb_model(training_df, validation_df, target_col='Oxygen')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0BSpHgS9gCq"
      },
      "source": [
        "# Model Comparison"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E-ixOVs09kQm"
      },
      "source": [
        "Linear Regression:\n",
        "Random Forest:\n",
        "LGBM:\n",
        "Neural Network:\n",
        "XG Boosting:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxQxMGZ89tBg"
      },
      "source": [
        "This best model was"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSWiTb-Y9xvc"
      },
      "source": [
        "# Feature Importance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqcRqzvc9wSa"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Ablation Study"
      ],
      "metadata": {
        "id": "dBm7xv-KhXnI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XsgitMfJhaZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyRCTO7x96Rx"
      },
      "source": [
        "# Insights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7M4J80pc99Xl"
      },
      "source": [
        "Based on our findings"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}